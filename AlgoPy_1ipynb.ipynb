{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPhetlYPlO+c2rQJkCsbLE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aagamaar/Algo_Trading_Python/blob/main/AlgoPy_1ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MOUNTED GOOGLE DRIVE"
      ],
      "metadata": {
        "id": "gH8Bo1BQO6QV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nda8qjnqNoH4",
        "outputId": "cf8afb91-1122-433d-dbfa-58b6b1183d08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully!\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING PROJECT DIRECTORY STRUCTURE"
      ],
      "metadata": {
        "id": "AKF-zls0PBTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Project Directory Structure\n",
        "import os\n",
        "\n",
        "# Defining the project root in Google Drive\n",
        "project_root = '/content/drive/MyDrive/algo_trading_prototype'\n",
        "\n",
        "# Creating the main project directory\n",
        "os.makedirs(project_root, exist_ok=True)\n",
        "print(f\"Project root created: {project_root}\")\n",
        "\n",
        "# Creating subdirectories\n",
        "subdirectories = [\n",
        "    'config',\n",
        "    'data',\n",
        "    'strategy',\n",
        "    'backtester',\n",
        "    'analytics',\n",
        "    'sheets',\n",
        "    'utils',\n",
        "    'logs' # Directory for log files\n",
        "]\n",
        "\n",
        "for subdir in subdirectories:\n",
        "    path = os.path.join(project_root, subdir)\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    print(f\"Created directory: {path}\")\n",
        "\n",
        "# I have added __init__.py files to make directories into Python packages\n",
        "# This is crucial for Python to recognize the folders as modules for importing.\n",
        "\n",
        "for pkg_dir in ['data', 'strategy', 'backtester', 'analytics', 'sheets', 'utils']:\n",
        "    with open(os.path.join(project_root, pkg_dir, '__init__.py'), 'w') as f:\n",
        "        pass # Created an empty __init__.py file\n",
        "    print(f\"Created __init__.py in {pkg_dir}\")\n",
        "\n",
        "print(\"\\nDirectory structure created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1SjuFktOJoK",
        "outputId": "fcb94444-4d20-48bf-90c3-4718d8076013"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project root created: /content/drive/MyDrive/algo_trading_prototype\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/config\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/data\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/strategy\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/backtester\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/analytics\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/sheets\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/utils\n",
            "Created directory: /content/drive/MyDrive/algo_trading_prototype/logs\n",
            "Created __init__.py in data\n",
            "Created __init__.py in strategy\n",
            "Created __init__.py in backtester\n",
            "Created __init__.py in analytics\n",
            "Created __init__.py in sheets\n",
            "Created __init__.py in utils\n",
            "\n",
            "Directory structure created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALLING THE DEPENDENCIES"
      ],
      "metadata": {
        "id": "7MvCiRG1QMSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the Dependencies\n",
        "# Used --quiet to suppress verbose output\n",
        "!pip install pandas numpy ta gspread oauth2client scikit-learn requests yfinance python-telegram-bot --quiet\n",
        "print(\"All required Python dependencies installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzg7TpdmPLt5",
        "outputId": "516e04ce-44f9-4288-f756-ee9826ba1fe2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All required Python dependencies installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HOLDS ALL CONFIGURATIONS"
      ],
      "metadata": {
        "id": "64ow2GkpQ75m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: config/settings.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/config/settings.py\n",
        "# config/settings.py\n",
        "\n",
        "# Stock Data API (using yfinance)\n",
        "# No API key is needed for basic yfinance usage\n",
        "STOCK_SYMBOLS = [\"RELIANCE.NS\", \"TCS.NS\", \"HDFCBANK.NS\"] # Three NIFTY 50 stocks for NSE.\n",
        "\n",
        "# Google Sheets\n",
        "GOOGLE_SHEET_ID = \"1W8nP1H7oIKwdy7m5dGii0lZcf_cKxn0mPSdzhAddm80\"\n",
        "TRADE_LOG_SHEET_NAME = \"Trade Log\"\n",
        "SUMMARY_PL_SHEET_NAME = \"Summary P&L\"\n",
        "WIN_RATIO_SHEET_NAME = \"Win Ratio\"\n",
        "\n",
        "# Strategy Parameters\n",
        "RSI_PERIOD = 14\n",
        "RSI_BUY_THRESHOLD = 30\n",
        "SHORT_MA_PERIOD = 20 # 20-Day Moving Average\n",
        "LONG_MA_PERIOD = 50  # 50-Day Moving Average\n",
        "\n",
        "# Backtesting Parameters\n",
        "BACKTEST_DURATION_MONTHS = 6\n",
        "\n",
        "# ML Model Parameters\n",
        "FEATURES = ['RSI', 'MACD', 'Volume', 'Close'] # Features for ML model\n",
        "TARGET = 'Next_Day_Movement' # Targets for ML model\n",
        "\n",
        "# Telegram Alerts (Bonus)\n",
        "TELEGRAM_BOT_TOKEN = \"8144019769:AAF-f7tW-XV9URIgJAAFyQgNtE0Tce0naXw\"\n",
        "TELEGRAM_CHAT_ID = \"1463467106\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mU0VgdkQTtP",
        "outputId": "9c129a88-2ce1-4b69-db9f-cd2d88580f89"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/config/settings.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SETTING UP LOGGING TO BOTH CONSOLE AND A FILE IN LOGS DIRECTORY"
      ],
      "metadata": {
        "id": "LnqI9HmOR4Dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/utils/logger.py\n",
        "# utils/logger.py\n",
        "\n",
        "import logging\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def setup_logging():\n",
        "    \"\"\"Configures logging for the application.\"\"\"\n",
        "    # Adjusted log_dir to be within your mounted Google Drive project structure.\n",
        "    log_dir = '/content/drive/MyDrive/algo_trading_prototype/logs'\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "\n",
        "    log_file = os.path.join(log_dir, f\"algo_trading_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
        "\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO, # Log INFO, WARNING, ERROR, CRITICAL messages\n",
        "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file), # Log to a file\n",
        "            logging.StreamHandler()        # Also print to console\n",
        "        ]\n",
        "    )\n",
        "    # Suppressing verbose logging from libraries to keep console clean\n",
        "    logging.getLogger('requests').setLevel(logging.WARNING)\n",
        "    logging.getLogger('urllib3').setLevel(logging.WARNING)\n",
        "    logging.getLogger('yfinance').setLevel(logging.WARNING)\n",
        "    logging.getLogger('gspread').setLevel(logging.WARNING)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0sF6e_GR3lY",
        "outputId": "4e5431b2-b1dd-435f-e7ed-15fb692de764"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/utils/logger.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HANDLES FETCHING STOCK DATA USING YFINANCE"
      ],
      "metadata": {
        "id": "4_Vh_wcvSvW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/data/data_fetcher.py\n",
        "# data/data_fetcher.py\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import logging\n",
        "from datetime import datetime, timedelta\n",
        "# Import BACKTEST_DURATION_MONTHS from settings for use in get_historical_data\n",
        "from config import settings # Import settings module directly\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class DataFetcher:\n",
        "    def __init__(self):\n",
        "        # yfinance doesn't require an API key for basic usage\n",
        "        pass\n",
        "\n",
        "    def fetch_historical_data(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Fetches historical stock data for a given symbol using yfinance.\n",
        "        Parameters:\n",
        "            symbol (str): Stock ticker symbol (e.g., \"RELIANCE.NS\").\n",
        "            start_date (str): Start date in 'YYYY-MM-DD' format.\n",
        "            end_date (str): End date in 'YYYY-MM-DD' format.\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with historical OHLCV data, or empty if fetching fails.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # yf.download returns a DataFrame directly with uppercase columns\n",
        "            df = yf.download(symbol, start=start_date, end=end_date, progress=False) # progress=False to reduce console output during download\n",
        "            if df.empty:\n",
        "                logger.warning(f\"No data fetched for {symbol} between {start_date} and {end_date}.\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            # Ensure we have the standard OHLCV columns and index is named 'Date'\n",
        "            df = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "            df.index.name = 'Date'\n",
        "            logger.info(f\"Successfully fetched historical data for {symbol}.\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error fetching data for {symbol} using yfinance: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "def get_historical_data(symbols: list, duration_months: int) -> dict:\n",
        "    \"\"\"\n",
        "    Fetches historical data for multiple symbols for the last 'duration_months' using yfinance.\n",
        "    Parameters:\n",
        "        symbols (list): List of stock ticker symbols.\n",
        "        duration_months (int): Number of months for which to fetch historical data.\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are symbols and values are pandas DataFrames.\n",
        "    \"\"\"\n",
        "    data_fetcher = DataFetcher()\n",
        "    all_data = {}\n",
        "    end_date = datetime.now()\n",
        "    # Calculate start date based on duration_months\n",
        "    start_date = end_date - timedelta(days=duration_months * 30) # Approximate 30 days per month\n",
        "\n",
        "    # Format dates as 'YYYY-MM-DD' for yfinance\n",
        "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
        "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "    for symbol in symbols:\n",
        "        df = data_fetcher.fetch_historical_data(symbol, start_date_str, end_date_str)\n",
        "        if not df.empty:\n",
        "            all_data[symbol] = df\n",
        "    return all_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0clOdM0IQ6lD",
        "outputId": "1f525313-c86c-49c0-cedc-f1b063bc3c73"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/data/data_fetcher.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCTIONS TO CALCULATE TECHNICAL INDICATORS LIKE RSI AND MOVING AVERAGES"
      ],
      "metadata": {
        "id": "dLoj7u1STRdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: strategy/indicators.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/strategy/indicators.py\n",
        "# strategy/indicators.py\n",
        "\n",
        "import pandas as pd\n",
        "import ta # Technical Analysis library\n",
        "\n",
        "def calculate_rsi(df: pd.DataFrame, window: int = 14) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Calculates Relative Strength Index (RSI).\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame with 'Close' prices.\n",
        "        window (int): The window period for RSI calculation.\n",
        "    Returns:\n",
        "        pd.Series: A Series containing RSI values.\n",
        "    \"\"\"\n",
        "    return ta.momentum.RSIIndicator(df[\"Close\"], window=window).rsi()\n",
        "\n",
        "def calculate_sma(df: pd.DataFrame, window: int) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Calculates Simple Moving Average (SMA).\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame with 'Close' prices.\n",
        "        window (int): The window period for SMA calculation.\n",
        "    Returns:\n",
        "        pd.Series: A Series containing SMA values.\n",
        "    \"\"\"\n",
        "    return ta.trend.SMAIndicator(df[\"Close\"], window=window).sma_indicator()\n",
        "\n",
        "def calculate_macd(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates Moving Average Convergence Divergence (MACD), Signal Line, and MACD Histogram.\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame with 'Close' prices.\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with 'MACD', 'MACD_Signal', and 'MACD_Hist' columns.\n",
        "    \"\"\"\n",
        "    macd_indicator = ta.trend.MACD(df[\"Close\"])\n",
        "    return pd.DataFrame({\n",
        "        'MACD': macd_indicator.macd(),\n",
        "        'MACD_Signal': macd_indicator.macd_signal(),\n",
        "        'MACD_Hist': macd_indicator.macd_diff()\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPNezTKCSpm7",
        "outputId": "803ec1bb-ad88-4682-8d86-096ba97b912b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/strategy/indicators.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTS THE TRADING STRATEGY LOGIC (RSI + Moving Average crossover)"
      ],
      "metadata": {
        "id": "FzRkLo0RTjO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: strategy/trading_strategy.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/strategy/trading_strategy.py\n",
        "# strategy/trading_strategy.py\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "from strategy.indicators import calculate_rsi, calculate_sma\n",
        "from config import settings # Import settings module directly\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class TradingStrategy:\n",
        "    def __init__(self):\n",
        "        self.rsi_period = settings.RSI_PERIOD\n",
        "        self.rsi_buy_threshold = settings.RSI_BUY_THRESHOLD\n",
        "        self.short_ma_period = settings.SHORT_MA_PERIOD\n",
        "        self.long_ma_period = settings.LONG_MA_PERIOD\n",
        "\n",
        "    def generate_signals(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Generates buy/sell signals based on RSI and Moving Average Crossover strategy.\n",
        "        Adds 'RSI', 'SMA_short', 'SMA_long', 'Signal' (1=Buy, -1=Sell, 0=Hold), and 'Position' columns.\n",
        "        Parameters:\n",
        "            df (pd.DataFrame): DataFrame with historical OHLCV data.\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with added indicator, signal, and position columns.\n",
        "        \"\"\"\n",
        "        if df.empty:\n",
        "            logger.warning(\"Empty DataFrame provided to generate_signals.\")\n",
        "            return df\n",
        "\n",
        "        # Calculate indicators\n",
        "        df['RSI'] = calculate_rsi(df, self.rsi_period)\n",
        "        df[f'SMA_{self.short_ma_period}'] = calculate_sma(df, self.short_ma_period)\n",
        "        df[f'SMA_{self.long_ma_period}'] = calculate_sma(df, self.long_ma_period)\n",
        "\n",
        "        df['Signal'] = 0 # Default to hold signal\n",
        "        df['Position'] = 0 # 1 for Long, 0 for Flat (no position)\n",
        "\n",
        "        # Drop NaN values introduced by indicator calculations before generating signals\n",
        "        df.dropna(subset=['RSI', f'SMA_{self.short_ma_period}', f'SMA_{self.long_ma_period}'], inplace=True)\n",
        "        if df.empty:\n",
        "            logger.warning(\"DataFrame became empty after dropping NaNs for indicator calculations.\")\n",
        "            return df\n",
        "\n",
        "        # Buy condition: RSI < 30 AND 20-DMA crosses above 50-DMA\n",
        "        # Check current day's MA relationship and previous day's relationship for a crossover\n",
        "        buy_condition = (df['RSI'] < self.rsi_buy_threshold) & \\\n",
        "                        (df[f'SMA_{self.short_ma_period}'] > df[f'SMA_{self.long_ma_period}']) & \\\n",
        "                        (df[f'SMA_{self.short_ma_period}'].shift(1) <= df[f'SMA_{self.long_ma_period}'].shift(1))\n",
        "\n",
        "        # Sell condition: 20-DMA crosses below 50-DMA (as a simple exit)\n",
        "        sell_condition = (df[f'SMA_{self.short_ma_period}'] < df[f'SMA_{self.long_ma_period}']) & \\\n",
        "                         (df[f'SMA_{self.short_ma_period}'].shift(1) >= df[f'SMA_{self.long_ma_period}'].shift(1))\n",
        "\n",
        "        # Apply signals\n",
        "        df.loc[buy_condition, 'Signal'] = 1\n",
        "        df.loc[sell_condition, 'Signal'] = -1\n",
        "\n",
        "        # Determine position based on signals\n",
        "        # This simulates opening a position on a buy signal and closing on a sell signal.\n",
        "        # It's a simplified approach for backtesting.\n",
        "        current_position = 0\n",
        "        position_list = []\n",
        "        for i in range(len(df)):\n",
        "            if df['Signal'].iloc[i] == 1: # Buy signal\n",
        "                current_position = 1 # Go long\n",
        "            elif df['Signal'].iloc[i] == -1: # Sell signal\n",
        "                current_position = 0 # Close position (go flat)\n",
        "            position_list.append(current_position)\n",
        "\n",
        "        df['Position'] = position_list\n",
        "        logger.info(\"Signals generated successfully.\")\n",
        "        return df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4kVEa2ZTdx7",
        "outputId": "d240545a-0de0-43d0-8ab8-4281c54ed15a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/strategy/trading_strategy.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIMULATES TRADING STRATEGY BASED ON HISTORICAL DATA"
      ],
      "metadata": {
        "id": "5jwlAbAvT2hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 9: backtester/backtester.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/backtester/backtester.py\n",
        "# backtester/backtester.py\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "from strategy.trading_strategy import TradingStrategy\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class Backtester:\n",
        "    def __init__(self):\n",
        "        self.strategy = TradingStrategy()\n",
        "        self.trade_log = [] # To store details of each trade\n",
        "\n",
        "    def run_backtest(self, symbol: str, historical_data: pd.DataFrame) -> dict:\n",
        "        \"\"\"\n",
        "        Runs a backtest on the given historical data for a symbol.\n",
        "        Simulates trades based on signals and calculates P&L.\n",
        "        Parameters:\n",
        "            symbol (str): Stock ticker symbol.\n",
        "            historical_data (pd.DataFrame): DataFrame with historical OHLCV data.\n",
        "        Returns:\n",
        "            dict: Dictionary containing backtest summary (initial/final capital, total P&L)\n",
        "                  and the detailed trade log. Returns empty dict if backtest cannot run.\n",
        "        \"\"\"\n",
        "        if historical_data.empty:\n",
        "            logger.warning(f\"No historical data provided for backtesting {symbol}.\")\n",
        "            return {}\n",
        "\n",
        "        df = historical_data.copy()\n",
        "        df = self.strategy.generate_signals(df)\n",
        "\n",
        "        # Filter out NaN rows that resulted from indicator calculations for cleaner iteration\n",
        "        df.dropna(subset=['RSI', 'Signal', 'Position'], inplace=True)\n",
        "        if df.empty:\n",
        "            logger.warning(f\"Data for {symbol} became empty after dropping NaNs for signals. Cannot backtest.\")\n",
        "            return {}\n",
        "\n",
        "        initial_capital = 100000 # Example initial capital\n",
        "        current_capital = initial_capital\n",
        "        position_open = False\n",
        "        buy_price = 0\n",
        "        shares_held = 0\n",
        "\n",
        "        # Reset trade_log for each backtest run\n",
        "        self.trade_log = []\n",
        "\n",
        "        for i in range(len(df)):\n",
        "            date = df.index[i]\n",
        "            close_price = df['Close'].iloc[i]\n",
        "            signal = df['Signal'].iloc[i]\n",
        "            current_position_status = df['Position'].iloc[i] # Current position from strategy\n",
        "\n",
        "            # Execute buy trade\n",
        "            if signal == 1 and not position_open: # Buy signal and no open position\n",
        "                shares_to_buy = int(current_capital / close_price) # Buy as many shares as possible\n",
        "                if shares_to_buy > 0:\n",
        "                    buy_price = close_price\n",
        "                    shares_held = shares_to_buy\n",
        "                    current_capital -= (shares_held * buy_price) # Deduct cost\n",
        "                    position_open = True\n",
        "                    self.trade_log.append({\n",
        "                        'Symbol': symbol,\n",
        "                        'Date': date.strftime('%Y-%m-%d'),\n",
        "                        'Type': 'BUY',\n",
        "                        'Price': round(buy_price, 2),\n",
        "                        'Shares': shares_held,\n",
        "                        'Capital_After_Trade': round(current_capital, 2),\n",
        "                        'P&L': 0.0 # P&L is realized on sell\n",
        "                    })\n",
        "                    logger.info(f\"{symbol} - {date.strftime('%Y-%m-%d')}: BUY at {buy_price:.2f} (Shares: {shares_held})\")\n",
        "\n",
        "            # Execute sell trade\n",
        "            elif signal == -1 and position_open: # Sell signal and there is an open position\n",
        "                sell_price = close_price\n",
        "                pnl = (sell_price - buy_price) * shares_held\n",
        "                current_capital += (shares_held * sell_price) # Add proceeds\n",
        "                position_open = False\n",
        "                self.trade_log.append({\n",
        "                    'Symbol': symbol,\n",
        "                    'Date': date.strftime('%Y-%m-%d'),\n",
        "                    'Type': 'SELL',\n",
        "                    'Price': round(sell_price, 2),\n",
        "                    'Shares': shares_held,\n",
        "                    'Capital_After_Trade': round(current_capital, 2),\n",
        "                    'P&L': round(pnl, 2)\n",
        "                })\n",
        "                logger.info(f\"{symbol} - {date.strftime('%Y-%m-%d')}: SELL at {sell_price:.2f} (P&L: {pnl:.2f})\")\n",
        "                buy_price = 0 # Reset buy price\n",
        "                shares_held = 0 # Reset shares held\n",
        "\n",
        "        # If a position is still open at the end of the backtest, close it forcibly\n",
        "        if position_open:\n",
        "            sell_price = df['Close'].iloc[-1]\n",
        "            pnl = (sell_price - buy_price) * shares_held\n",
        "            current_capital += (shares_held * sell_price)\n",
        "            self.trade_log.append({\n",
        "                'Symbol': symbol,\n",
        "                'Date': df.index[-1].strftime('%Y-%m-%d'),\n",
        "                'Type': 'SELL (Forced Exit)', # Indicate a forced exit at end of backtest period\n",
        "                'Price': round(sell_price, 2),\n",
        "                'Shares': shares_held,\n",
        "                'Capital_After_Trade': round(current_capital, 2),\n",
        "                'P&L': round(pnl, 2)\n",
        "            })\n",
        "            logger.info(f\"{symbol} - Forced SELL at {sell_price:.2f} (P&L: {pnl:.2f}) at end of backtest.\")\n",
        "\n",
        "        total_pnl = current_capital - initial_capital\n",
        "        logger.info(f\"Backtest for {symbol} completed. Total P&L: {total_pnl:.2f}\")\n",
        "\n",
        "        return {\n",
        "            'symbol': symbol,\n",
        "            'initial_capital': initial_capital,\n",
        "            'final_capital': current_capital,\n",
        "            'total_pnl': total_pnl,\n",
        "            'trade_log': pd.DataFrame(self.trade_log) # Convert to DataFrame for easier handling\n",
        "        }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wacWdbGATvov",
        "outputId": "6db8bc46-f361-43b8-efa4-5bc742c9ee76"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/backtester/backtester.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTS THE MACHINE LEARNING MODEL FOR NEXT DAY MOVEMENT PREDICTION"
      ],
      "metadata": {
        "id": "v38kah48hg1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: analytics/ml_predictor.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/analytics/ml_predictor.py\n",
        "# analytics/ml_predictor.py\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import logging\n",
        "from strategy.indicators import calculate_rsi, calculate_macd # Assuming MACD calc is added\n",
        "from config import settings # Import settings to access FEATURES and TARGET\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class MLPredictor:\n",
        "    def __init__(self, model_type: str = 'decision_tree'):\n",
        "        \"\"\"\n",
        "        Initializes the ML Predictor with a specified model type.\n",
        "        Parameters:\n",
        "            model_type (str): 'decision_tree' or 'logistic_regression'.\n",
        "        \"\"\"\n",
        "        if model_type == 'decision_tree':\n",
        "            self.model = DecisionTreeClassifier(random_state=42)\n",
        "        elif model_type == 'logistic_regression':\n",
        "            self.model = LogisticRegression(random_state=42, solver='liblinear')\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported model_type. Choose 'decision_tree' or 'logistic_regression'.\")\n",
        "        self.trained = False # Flag to check if model has been trained\n",
        "\n",
        "    def prepare_data_for_ml(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Prepares data for ML model training by adding features (RSI, MACD, Volume)\n",
        "        and the target variable (Next_Day_Movement).\n",
        "        Parameters:\n",
        "            df (pd.DataFrame): DataFrame with historical OHLCV data.\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame with added features and target column, or empty if input is empty.\n",
        "        \"\"\"\n",
        "        if df.empty:\n",
        "            logger.warning(\"Empty DataFrame provided for ML data preparation.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Calculate features\n",
        "        df['RSI'] = calculate_rsi(df, window=settings.RSI_PERIOD) # Use RSI period from settings\n",
        "        macd_df = calculate_macd(df)\n",
        "        df = df.join(macd_df)\n",
        "\n",
        "        # Calculate next-day close movement as target (1 for Up, 0 for Down/No Change)\n",
        "        # Shift(-1) means the close price of the *next* row\n",
        "        df['Next_Day_Close'] = df['Close'].shift(-1)\n",
        "        # Target: 1 if next day's close is higher, 0 otherwise\n",
        "        df['Next_Day_Movement'] = (df['Next_Day_Close'] > df['Close']).astype(int)\n",
        "\n",
        "        # Drop rows with NaN values (due to indicator calculation or Next_Day_Close for last row)\n",
        "        df.dropna(subset=settings.FEATURES + ['Next_Day_Movement'], inplace=True)\n",
        "        return df\n",
        "\n",
        "    def train_model(self, df: pd.DataFrame, features: list, target: str):\n",
        "        \"\"\"\n",
        "        Trains the ML model and evaluates its performance.\n",
        "        Parameters:\n",
        "            df (pd.DataFrame): Prepared DataFrame with features and target.\n",
        "            features (list): List of column names to use as features.\n",
        "            target (str): Name of the target column.\n",
        "        Returns:\n",
        "            tuple: (accuracy, classification_report_string). Returns (0.0, \"\") if training fails.\n",
        "        \"\"\"\n",
        "        if df.empty or not all(col in df.columns for col in features + [target]):\n",
        "            logger.warning(\"Insufficient data or missing columns for ML training.\")\n",
        "            self.trained = False\n",
        "            return 0.0, \"\"\n",
        "\n",
        "        X = df[features]\n",
        "        y = df[target]\n",
        "\n",
        "        # Handle cases where only one class is present in the target variable\n",
        "        if len(y.unique()) < 2:\n",
        "            logger.warning(f\"Only one class present in target variable for ML training (symbol has no 'Up' or 'Down' movements in data). Skipping training.\")\n",
        "            self.trained = False\n",
        "            return 0.0, \"Only one class in target\"\n",
        "\n",
        "        try:\n",
        "            # Stratify ensures that the train/test split maintains the proportion of classes\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "        except ValueError as e:\n",
        "            logger.warning(f\"Could not split data for ML training due to: {e}. Check data balance or size.\")\n",
        "            self.trained = False\n",
        "            return 0.0, str(e)\n",
        "\n",
        "        self.model.fit(X_train, y_train)\n",
        "        y_pred = self.model.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        # zero_division=0 prevents warnings when a class has no predicted samples\n",
        "        report = classification_report(y_test, y_pred, zero_division=0)\n",
        "\n",
        "        logger.info(f\"ML Model Training Complete (Model: {type(self.model).__name__}):\")\n",
        "        logger.info(f\"Accuracy: {accuracy:.4f}\")\n",
        "        logger.info(f\"Classification Report:\\n{report}\")\n",
        "        self.trained = True\n",
        "        return accuracy, report\n",
        "\n",
        "    def predict_next_day_movement(self, latest_data_df: pd.DataFrame, features: list) -> int:\n",
        "        \"\"\"\n",
        "        Predicts the next day's movement (1 for Up, 0 for Down/No Change) based on the trained model.\n",
        "        `latest_data_df` should contain enough historical rows to calculate required indicators\n",
        "        for the *last* data point.\n",
        "        Parameters:\n",
        "            latest_data_df (pd.DataFrame): DataFrame containing recent historical OHLCV data.\n",
        "                                           Should include enough rows to calculate all features.\n",
        "            features (list): List of feature column names used during training.\n",
        "        Returns:\n",
        "            int: 1 for 'Up', 0 for 'Down/No Change', -1 if prediction cannot be made (e.g., not trained, no data).\n",
        "        \"\"\"\n",
        "        if not self.trained:\n",
        "            logger.warning(\"ML model is not trained. Cannot make prediction.\")\n",
        "            return -1\n",
        "\n",
        "        if latest_data_df.empty:\n",
        "            logger.warning(\"Empty DataFrame provided for ML prediction.\")\n",
        "            return -1\n",
        "\n",
        "        # Prepare the data to get the latest features, similar to training data prep\n",
        "        processed_df = self.prepare_data_for_ml(latest_data_df.copy())\n",
        "        if processed_df.empty:\n",
        "            logger.warning(\"Could not process latest data for prediction after feature engineering.\")\n",
        "            return -1\n",
        "\n",
        "        # The last row of `processed_df` contains the latest calculated features\n",
        "        # and its 'Next_Day_Movement' would be NaN (which is fine for prediction input)\n",
        "        try:\n",
        "            latest_features_row = processed_df[features].iloc[-1]\n",
        "            # Reshape for prediction (sklearn expects 2D array, even for a single sample)\n",
        "            prediction_input = latest_features_row.to_frame().T\n",
        "            prediction = self.model.predict(prediction_input)[0]\n",
        "            logger.info(f\"Next day movement prediction: {'Up' if prediction == 1 else 'Down/No Change'}\")\n",
        "            return int(prediction)\n",
        "        except IndexError:\n",
        "            logger.warning(\"Not enough data points in processed_df for prediction after feature engineering.\")\n",
        "            return -1\n",
        "        except KeyError as e:\n",
        "            logger.warning(f\"Missing feature for prediction: {e}. Check FEATURES in settings.py and data preparation.\")\n",
        "            return -1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpi8UXWfT0pv",
        "outputId": "2221da7a-25d7-42ba-f775-869619e029d2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/analytics/ml_predictor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MANAGES INTERACTIONS WITH GOOGLE SHEETS"
      ],
      "metadata": {
        "id": "LZyv5x8Mh2zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: sheets/google_sheets_manager.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/sheets/google_sheets_manager.py\n",
        "# sheets/google_sheets_manager.py\n",
        "\n",
        "import gspread\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os # Import os to set environment variable\n",
        "from config import settings # Import settings module directly\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class GoogleSheetsManager:\n",
        "    def __init__(self):\n",
        "        self.spreadsheet = None\n",
        "        try:\n",
        "            # IMPORTANT: For gspread to find your credentials.json,\n",
        "            # you can either place it in a default gspread location\n",
        "            # OR set the GOOGLE_APPLICATION_CREDENTIALS environment variable.\n",
        "            # In Colab, upload your 'credentials.json' to your Drive,\n",
        "            # for example, in the root of your project:\n",
        "            # /content/drive/MyDrive/algo_trading_prototype/credentials.json\n",
        "            # Then set the environment variable:\n",
        "            os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/drive/MyDrive/algo_trading_prototype/credentials.json\"\n",
        "            self.gc = gspread.service_account() # gspread will now look for the path in the env var\n",
        "\n",
        "            self.spreadsheet = self.gc.open_by_id(settings.GOOGLE_SHEET_ID)\n",
        "            logger.info(f\"Successfully connected to Google Sheet: {self.spreadsheet.title}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error connecting to Google Sheets. \"\n",
        "                         f\"Please ensure:\\n\"\n",
        "                         f\"1. Google Sheets API is enabled in your GCP project.\\n\"\n",
        "                         f\"2. Your 'credentials.json' is correctly placed at \"\n",
        "                         f\"'/content/drive/MyDrive/algo_trading_prototype/credentials.json'.\\n\"\n",
        "                         f\"3. The Google Sheet (ID: {settings.GOOGLE_SHEET_ID}) is shared with the service account email \"\n",
        "                         f\"(found in 'credentials.json').\\n\"\n",
        "                         f\"Error: {e}\")\n",
        "            self.spreadsheet = None\n",
        "\n",
        "    def _get_or_create_worksheet(self, sheet_name: str):\n",
        "        \"\"\"Helper to get a worksheet by name or create it if it doesn't exist.\"\"\"\n",
        "        if not self.spreadsheet:\n",
        "            logger.error(f\"Cannot get/create worksheet '{sheet_name}'. Not connected to Google Sheets.\")\n",
        "            return None\n",
        "        try:\n",
        "            worksheet = self.spreadsheet.worksheet(sheet_name)\n",
        "            logger.debug(f\"Found worksheet: {sheet_name}\")\n",
        "            return worksheet\n",
        "        except gspread.exceptions.WorksheetNotFound:\n",
        "            logger.info(f\"Worksheet '{sheet_name}' not found, creating it...\")\n",
        "            # Default rows/cols for new sheet. Adjust if your data is much larger.\n",
        "            worksheet = self.spreadsheet.add_worksheet(title=sheet_name, rows=2000, cols=50)\n",
        "            logger.info(f\"Created new worksheet: {sheet_name}\")\n",
        "            return worksheet\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting/creating worksheet '{sheet_name}': {e}\")\n",
        "            return None\n",
        "\n",
        "    def log_trade_signals(self, trade_log_df: pd.DataFrame):\n",
        "        \"\"\"Logs trade signals to the 'Trade Log' tab in Google Sheets.\"\"\"\n",
        "        if trade_log_df.empty:\n",
        "            logger.info(\"No trade logs to record.\")\n",
        "            return\n",
        "\n",
        "        worksheet = self._get_or_create_worksheet(settings.TRADE_LOG_SHEET_NAME)\n",
        "        if not worksheet:\n",
        "            return\n",
        "\n",
        "        # Ensure Date column is formatted as string for Google Sheets\n",
        "        trade_log_df['Date'] = trade_log_df['Date'].astype(str)\n",
        "        data_to_upload = trade_log_df.values.tolist()\n",
        "\n",
        "        try:\n",
        "            # Get existing header and expected header\n",
        "            existing_header = worksheet.row_values(1)\n",
        "            expected_header = trade_log_df.columns.tolist()\n",
        "\n",
        "            # If header is missing or mismatch, clear sheet and write header + data\n",
        "            if not existing_header or existing_header != expected_header:\n",
        "                worksheet.clear() # Clear all contents (data and formatting)\n",
        "                worksheet.update([expected_header], 'A1') # Write header\n",
        "                logger.info(f\"Header updated/added to '{settings.TRADE_LOG_SHEET_NAME}' worksheet.\")\n",
        "                # Append data after header, ensuring we start from the second row\n",
        "                worksheet.append_rows(data_to_upload)\n",
        "            else:\n",
        "                # If header is present and correct, just append new rows\n",
        "                worksheet.append_rows(data_to_upload)\n",
        "\n",
        "            logger.info(f\"Logged {len(trade_log_df)} trade signals to '{settings.TRADE_LOG_SHEET_NAME}'.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error logging trade signals to Google Sheets: {e}\")\n",
        "\n",
        "    def update_summary_pnl(self, symbol_pnl_data: dict):\n",
        "        \"\"\"Updates the 'Summary P&L' tab with overall P&L for each symbol.\"\"\"\n",
        "        if not symbol_pnl_data:\n",
        "            logger.info(\"No summary P&L data to record.\")\n",
        "            return\n",
        "\n",
        "        worksheet = self._get_or_create_worksheet(settings.SUMMARY_PL_SHEET_NAME)\n",
        "        if not worksheet:\n",
        "            return\n",
        "\n",
        "        # Prepare data for summary P&L\n",
        "        summary_data = [\n",
        "            [\"Symbol\", \"Initial Capital\", \"Final Capital\", \"Total P&L\"]\n",
        "        ]\n",
        "        for symbol, data in symbol_pnl_data.items():\n",
        "            summary_data.append([\n",
        "                symbol,\n",
        "                data.get('initial_capital', 0),\n",
        "                data.get('final_capital', 0),\n",
        "                data.get('total_pnl', 0)\n",
        "            ])\n",
        "\n",
        "        try:\n",
        "            worksheet.clear() # Clear existing data before updating\n",
        "            worksheet.update(summary_data) # Update with new summary\n",
        "            logger.info(f\"Updated '{settings.SUMMARY_PL_SHEET_NAME}' worksheet.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error updating summary P&L to Google Sheets: {e}\")\n",
        "\n",
        "    def update_win_ratio(self, trade_log_df: pd.DataFrame):\n",
        "        \"\"\"Calculates and updates the 'Win Ratio' tab in Google Sheets.\"\"\"\n",
        "        if trade_log_df.empty:\n",
        "            logger.info(\"No trade data to calculate win ratio.\")\n",
        "            return\n",
        "\n",
        "        worksheet = self._get_or_create_worksheet(settings.WIN_RATIO_SHEET_NAME)\n",
        "        if not worksheet:\n",
        "            return\n",
        "\n",
        "        # Filter for sell trades (where P&L is realized)\n",
        "        sell_trades = trade_log_df[trade_log_df['Type'].str.contains('SELL', na=False)]\n",
        "        if sell_trades.empty:\n",
        "            logger.info(\"No sell trades to calculate win ratio.\")\n",
        "            # Still update the sheet to show zero values if no trades\n",
        "            win_ratio_data = [\n",
        "                [\"Metric\", \"Value\"],\n",
        "                [\"Total Trades (Sell)\", 0],\n",
        "                [\"Winning Trades\", 0],\n",
        "                [\"Losing Trades\", 0],\n",
        "                [\"Win Ratio (%)\", 0.0]\n",
        "            ]\n",
        "            worksheet.clear()\n",
        "            worksheet.update(win_ratio_data)\n",
        "            return\n",
        "\n",
        "        total_trades = len(sell_trades)\n",
        "        winning_trades = len(sell_trades[sell_trades['P&L'] > 0])\n",
        "        losing_trades = len(sell_trades[sell_trades['P&L'] <= 0])\n",
        "\n",
        "        win_ratio = (winning_trades / total_trades) * 100 if total_trades > 0 else 0\n",
        "\n",
        "        win_ratio_data = [\n",
        "            [\"Metric\", \"Value\"],\n",
        "            [\"Total Trades (Sell)\", total_trades],\n",
        "            [\"Winning Trades\", winning_trades],\n",
        "            [\"Losing Trades\", losing_trades],\n",
        "            [\"Win Ratio (%)\", round(win_ratio, 2)]\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            worksheet.clear() # Clear existing data\n",
        "            worksheet.update(win_ratio_data) # Update with new win ratio data\n",
        "            logger.info(f\"Updated '{settings.WIN_RATIO_SHEET_NAME}' worksheet.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error updating win ratio to Google Sheets: {e}\")\n",
        "\n",
        "    def get_signal_alerts(self, symbol: str, date: str, signal_type: str, price: float):\n",
        "        \"\"\"\n",
        "        Generates a formatted string for a trade signal alert.\n",
        "        \"\"\"\n",
        "        return f\"🚨 TRADE ALERT 🚨\\nSymbol: {symbol}\\nDate: {date}\\nSignal: {signal_type}\\nPrice: {price:.2f}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a355eEPdh02M",
        "outputId": "89cb6852-ec5c-4ef9-9814-2517a0bfc624"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/sheets/google_sheets_manager.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HANDLES TELEGRAM MESSAGES"
      ],
      "metadata": {
        "id": "5VbUITMXiVbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: utils/alerts.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/utils/alerts.py\n",
        "# utils/alerts.py\n",
        "\n",
        "import requests\n",
        "import logging\n",
        "from config import settings # Import settings module directly\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def send_telegram_message(message: str):\n",
        "    \"\"\"\n",
        "    Sends a message to a specified Telegram chat.\n",
        "    Requires TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID from config/settings.py.\n",
        "    Parameters:\n",
        "        message (str): The text message to send.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        bot_token = settings.TELEGRAM_BOT_TOKEN\n",
        "        chat_id = settings.TELEGRAM_CHAT_ID\n",
        "    except AttributeError:\n",
        "        logger.error(\"Telegram bot token or chat ID not found in settings.py. Skipping Telegram alert.\")\n",
        "        return\n",
        "\n",
        "    if not bot_token or not chat_id:\n",
        "        logger.warning(\"Telegram BOT_TOKEN or CHAT_ID is not configured. Skipping alert.\")\n",
        "        return\n",
        "\n",
        "    url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
        "    payload = {\n",
        "        \"chat_id\": chat_id,\n",
        "        \"text\": message,\n",
        "        \"parse_mode\": \"Markdown\" # Allows basic markdown formatting in message\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(url, json=payload)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        logger.info(\"Telegram message sent successfully.\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logger.error(f\"Error sending Telegram message: {e}\")"
      ],
      "metadata": {
        "id": "mIYasGnZiKRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9021436-0dfb-4535-c448-f7d3eda73c1e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/utils/alerts.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLACEHOLDER FOR THIS PROTOTYPE"
      ],
      "metadata": {
        "id": "WTkuaMJRklL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: analytics/portfolio_analytics.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/analytics/portfolio_analytics.py\n",
        "# analytics/portfolio_analytics.py\n",
        "\n",
        "# This file is a placeholder. Its functionalities (P&L, Win Ratio)\n",
        "# are integrated directly into Backtester and GoogleSheetsManager for simplicity.\n",
        "# For more complex analytics (e.g., Sharpe Ratio, Max Drawdown), you would\n",
        "# implement them here."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2COS9PskbBx",
        "outputId": "bdc450e0-54a4-4630-b68e-300a3afd845e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/analytics/portfolio_analytics.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: main.py\n",
        "%%writefile /content/drive/MyDrive/algo_trading_prototype/main.py\n",
        "# main.py\n",
        "\n",
        "import logging\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Define the project root directly within main.py\n",
        "# This ensures that main.py itself knows where the root of your project is,\n",
        "# regardless of how it's executed, which helps Python find your modules.\n",
        "project_root = '/content/drive/MyDrive/algo_trading_prototype'\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "    # Note: If you modify this or any other module, you might need to\n",
        "    # restart your Colab runtime to ensure changes are picked up due to Python's module caching.\n",
        "\n",
        "# Now, import modules using their top-level package names relative to project_root\n",
        "from config import settings\n",
        "from utils import logger\n",
        "from data import data_fetcher\n",
        "from backtester import backtester\n",
        "from analytics import ml_predictor\n",
        "from sheets import google_sheets_manager\n",
        "from utils import alerts # Bonus: Telegram alerts\n",
        "\n",
        "# Setup logging. This needs to be called to configure loggers globally.\n",
        "logger.setup_logging()\n",
        "main_logger = logging.getLogger(__name__) # Get a specific logger for the main script\n",
        "\n",
        "def run_algo_prototype():\n",
        "    \"\"\"\n",
        "    Main function to run the algo-trading prototype.\n",
        "    Orchestrates data fetching, strategy application, backtesting,\n",
        "    ML prediction, and Google Sheets logging.\n",
        "    \"\"\"\n",
        "    main_logger.info(\"Starting Algo-Trading Prototype...\")\n",
        "\n",
        "    # Initialize components\n",
        "    sheets_manager = google_sheets_manager.GoogleSheetsManager()\n",
        "    backtester_instance = backtester.Backtester()\n",
        "    ml_predictor_instance = ml_predictor.MLPredictor(model_type='decision_tree') # Can be 'logistic_regression'\n",
        "\n",
        "    all_trade_logs = pd.DataFrame() # To aggregate trade logs from all symbols\n",
        "    symbol_pnl_results = {} # To store P&L summary per symbol\n",
        "    ml_accuracies = {} # To store ML model accuracies per symbol\n",
        "\n",
        "    # --- 1. Data Ingestion & ML Model Training ---\n",
        "    main_logger.info(f\"Fetching historical data for {settings.STOCK_SYMBOLS} for {settings.BACKTEST_DURATION_MONTHS} months...\")\n",
        "    historical_data = data_fetcher.get_historical_data(settings.STOCK_SYMBOLS, settings.BACKTEST_DURATION_MONTHS)\n",
        "\n",
        "    if not historical_data:\n",
        "        main_logger.error(\"No historical data fetched. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Train ML model for each stock using its historical data\n",
        "    main_logger.info(\"Preparing data and training ML model for each stock...\")\n",
        "    for symbol, df in historical_data.items():\n",
        "        if not df.empty:\n",
        "            ml_data = ml_predictor_instance.prepare_data_for_ml(df.copy())\n",
        "            if not ml_data.empty:\n",
        "                accuracy, _ = ml_predictor_instance.train_model(ml_data, settings.FEATURES, settings.TARGET)\n",
        "                ml_accuracies[symbol] = accuracy\n",
        "            else:\n",
        "                main_logger.warning(f\"Could not prepare ML data for {symbol}.\")\n",
        "        else:\n",
        "            main_logger.warning(f\"No data for {symbol} to train ML model.\")\n",
        "\n",
        "    main_logger.info(f\"ML Model Accuracies: {ml_accuracies}\")\n",
        "\n",
        "    # --- 2. Run Backtest for each stock ---\n",
        "    for symbol, df in historical_data.items():\n",
        "        if df.empty:\n",
        "            main_logger.warning(f\"Skipping backtest for {symbol} due to no data.\")\n",
        "            continue\n",
        "\n",
        "        main_logger.info(f\"Running backtest for {symbol}...\")\n",
        "        results = backtester_instance.run_backtest(symbol, df.copy())\n",
        "        if results:\n",
        "            symbol_pnl_results[symbol] = {\n",
        "                'initial_capital': results['initial_capital'],\n",
        "                'final_capital': results['final_capital'],\n",
        "                'total_pnl': results['total_pnl']\n",
        "            }\n",
        "            if not results['trade_log'].empty:\n",
        "                # Concatenate trade logs from each symbol into one DataFrame\n",
        "                all_trade_logs = pd.concat([all_trade_logs, results['trade_log']], ignore_index=True)\n",
        "        else:\n",
        "            main_logger.warning(f\"Backtest for {symbol} yielded no results.\")\n",
        "\n",
        "    # --- 3. Google Sheets Automation ---\n",
        "    # Log all aggregated trade signals\n",
        "    if not all_trade_logs.empty:\n",
        "        main_logger.info(\"Logging trade signals to Google Sheets...\")\n",
        "        sheets_manager.log_trade_signals(all_trade_logs)\n",
        "        # Update win ratio based on all logs\n",
        "        sheets_manager.update_win_ratio(all_trade_logs)\n",
        "    else:\n",
        "        main_logger.info(\"No trade logs to write to Google Sheets.\")\n",
        "\n",
        "    # Update summary P&L\n",
        "    if symbol_pnl_results:\n",
        "        main_logger.info(\"Updating summary P&L in Google Sheets...\")\n",
        "        sheets_manager.update_summary_pnl(symbol_pnl_results)\n",
        "    else:\n",
        "        main_logger.info(\"No summary P&L to write to Google Sheets.\")\n",
        "\n",
        "    # --- 4. Generate Current Buy/Sell Signals and ML Predictions ---\n",
        "    main_logger.info(\"Generating current (latest date) buy/sell signals and ML predictions...\")\n",
        "    for symbol, df in historical_data.items():\n",
        "        if df.empty:\n",
        "            main_logger.warning(f\"Cannot generate signal for {symbol}: no data.\")\n",
        "            continue\n",
        "\n",
        "        # Get enough historical data points to calculate all indicators for the latest day\n",
        "        required_rows_for_indicators = max(settings.RSI_PERIOD, settings.SHORT_MA_PERIOD, settings.LONG_MA_PERIOD) + 1 # +1 for current day's signal\n",
        "        latest_data_for_signal = df.tail(required_rows_for_indicators).copy()\n",
        "\n",
        "        if latest_data_for_signal.empty:\n",
        "            main_logger.warning(f\"Not enough recent data for {symbol} to generate current signal after indicator calculation.\")\n",
        "            continue\n",
        "\n",
        "        # Re-run strategy on the latest data to get the current day's signal\n",
        "        processed_latest_data = backtester_instance.strategy.generate_signals(latest_data_for_signal)\n",
        "\n",
        "        # Check if the last row (current day) has valid signal/data\n",
        "        if processed_latest_data.empty or processed_latest_data.iloc[-1].isnull().any():\n",
        "            main_logger.warning(f\"Could not generate clean signal for {symbol} for the latest date after processing.\")\n",
        "            current_signal = 0 # Default to hold if signal is unreliable\n",
        "            current_close = df['Close'].iloc[-1] if not df.empty else 0\n",
        "            current_date = df.index[-1].strftime('%Y-%m-%d') if not df.empty else \"N/A\"\n",
        "        else:\n",
        "            current_signal = processed_latest_data['Signal'].iloc[-1]\n",
        "            current_close = processed_latest_data['Close'].iloc[-1]\n",
        "            current_date = processed_latest_data.index[-1].strftime('%Y-%m-%d')\n",
        "\n",
        "        signal_type = \"HOLD\"\n",
        "        if current_signal == 1:\n",
        "            signal_type = \"BUY\"\n",
        "        elif current_signal == -1:\n",
        "            signal_type = \"SELL\"\n",
        "\n",
        "        main_logger.info(f\"[{symbol}] Latest Strategy Signal ({current_date}): {signal_type} at {current_close:.2f}\")\n",
        "\n",
        "        # ML prediction for next day movement\n",
        "        # Need enough data points for ML features (RSI, MACD, Volume) for the current day\n",
        "        # `prepare_data_for_ml` handles dropping NaNs, so pass a sufficient window of recent data\n",
        "        ml_prediction_input_data = df.tail(max(settings.RSI_PERIOD, 26) + 2).copy() # MACD needs up to 26 periods + 1 for next day shift\n",
        "        if not ml_prediction_input_data.empty and ml_predictor_instance.trained:\n",
        "            next_day_pred = ml_predictor_instance.predict_next_day_movement(ml_prediction_input_data, settings.FEATURES)\n",
        "            ml_pred_text = \"Up\" if next_day_pred == 1 else (\"Down/No Change\" if next_day_pred == 0 else \"N/A - Prediction Failed\")\n",
        "            main_logger.info(f\"[{symbol}] Next Day ML Prediction: {ml_pred_text}\")\n",
        "        else:\n",
        "            ml_pred_text = \"N/A - Model Not Trained or Insufficient Data\"\n",
        "            main_logger.warning(f\"[{symbol}] {ml_pred_text}\")\n",
        "\n",
        "        # Bonus: Telegram Alert Integration\n",
        "        if current_signal != 0 or next_day_pred != -1: # Alert for strategy signals or if ML made a valid prediction\n",
        "            alert_message = sheets_manager.get_signal_alerts(symbol, current_date, signal_type, current_close)\n",
        "            alert_message += f\"\\nML Prediction (Next Day): {ml_pred_text}\"\n",
        "            alerts.send_telegram_message(alert_message)\n",
        "\n",
        "    main_logger.info(\"Algo-Trading Prototype finished.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_algo_prototype()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jna6aUWBkkZb",
        "outputId": "219deffe-89c5-4359-fb39-d8c930defd04"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/algo_trading_prototype/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FJrmhP6Ik53D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}